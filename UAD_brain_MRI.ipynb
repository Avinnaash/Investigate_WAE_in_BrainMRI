{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "UAD_brain_MRI.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1-a9c5c4qaiK",
        "P2WmjqCqp3S4",
        "9Oc6ISRcqJMI",
        "qdIb36bv-yji",
        "U0D7zuB62DR0"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cjIFrxl4xpb"
      },
      "source": [
        "# Investigate Wasserstein Auto-Encoder for Unsupervised Anomaly Detection in brain MRI\n",
        "\n",
        "This is the code used in my Master Research Project done from July 2020 until January 2021.\n",
        "\n",
        "\n",
        "***Disclaimer:***\n",
        "*The code has been cleaned and polished for the sake of clarity and reproducibility, and even though it has been checked thoroughly, it might contain bugs or mistakes. Please do not hesitate to open an issue or contact the authors to inform of any problem you may find within this repository. Some hyperparameters may also have to be adjusted!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYcltK7e6r5A"
      },
      "source": [
        "## System Configuration & Preparation\n",
        "\n",
        "### Imports and installation of the required libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI-mX3ic4zBC",
        "outputId": "ee270880-207f-465b-9f61-fff2a45843ea"
      },
      "source": [
        "# from google.colab import drive\n",
        "# from google.colab import files\n",
        "import os, glob\n",
        "! pip install pynrrd\n",
        "! pip install SimpleITK\n",
        "! pip install bunch\n",
        "! pip install nibabel\n",
        "! pip install medpy\n",
        "! pip install opencv-python"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pynrrd\n",
            "  Downloading https://files.pythonhosted.org/packages/92/00/ef17d52fd125f357d7ead95e823091b2344194d34ce94e2fe839184f48e7/pynrrd-0.4.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from pynrrd) (1.19.5)\n",
            "Installing collected packages: pynrrd\n",
            "Successfully installed pynrrd-0.4.2\n",
            "Collecting SimpleITK\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/85/6a7ce61f07cdaca722dd64f028b5678fb0a9e1bf66f534c2f8dd2eb78490/SimpleITK-2.0.2-cp36-cp36m-manylinux2010_x86_64.whl (47.4MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4MB 67kB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.0.2\n",
            "Collecting bunch\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/bf/a4cf1779a4ffb4f610903fa08e15d1f4a8a2f4e3353a02afbe097c5bf4a8/bunch-1.0.1.tar.gz\n",
            "Building wheels for collected packages: bunch\n",
            "  Building wheel for bunch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bunch: filename=bunch-1.0.1-cp36-none-any.whl size=7076 sha256=d7d8eadae613d03bf61025ad14d40649eb2d44866ebc7dab23ed67e541908228\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/0f/19/fbbf81e5764e6d8b74501c4357a88c14c94466ec777c03734c\n",
            "Successfully built bunch\n",
            "Installing collected packages: bunch\n",
            "Successfully installed bunch-1.0.1\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from nibabel) (1.19.5)\n",
            "Collecting medpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/70/c1fd5dd60242eee81774696ea7ba4caafac2bad8f028bba94b1af83777d7/MedPy-0.4.0.tar.gz (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from medpy) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from medpy) (1.19.5)\n",
            "Requirement already satisfied: SimpleITK>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from medpy) (2.0.2)\n",
            "Building wheels for collected packages: medpy\n",
            "  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for medpy: filename=MedPy-0.4.0-cp36-cp36m-linux_x86_64.whl size=753439 sha256=084496d4a7a9b6d5f18c403039df0fc5e037dbe49a8505d98a8176ded882dd6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/c9/9c/2c6281c7a72b9fb1570862a4f028af7ce38405008354fbf870\n",
            "Successfully built medpy\n",
            "Installing collected packages: medpy\n",
            "Successfully installed medpy-0.4.0\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlBFG8cb9zRr"
      },
      "source": [
        "### Get Code\n",
        "Clone Code from github.com"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmL1urt8-F1a"
      },
      "source": [
        "# ! git clone https://github.com/irfixq/Investigate_WAE_in_BrainMRI\n",
        "# ! cd Investigate_WAE_in_BrainMRI"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo5Rut3WcSHH"
      },
      "source": [
        "### Google Drive mount\n",
        "\n",
        "*Optional:* Mounting Google Drive to access datasets or can upload manually onto GoogleColab runtime session storage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBFA_7f5cUe0"
      },
      "source": [
        "# drive.mount('gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrvpEjhXxVgV"
      },
      "source": [
        "Check Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHYCb_jnxVgW",
        "outputId": "e3ae11af-6a31-4ca5-f362-b9432bb94fec"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\Irfixq\\\\Desktop\\\\P2\\\\Code 1\\\\Unsupervised_Anomaly_Detection_Brain_MRI-master'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRn8HOi7rSvV"
      },
      "source": [
        "### Tensorboard and tunneling\n",
        "Install ngrok for tunneling "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc71w6qerQtF",
        "outputId": "12b6f32a-5baf-4715-dfd6-dc5172517158"
      },
      "source": [
        "if os.path.exists(\"ngrok-stable-linux-amd64.zip\"):\n",
        "    os.remove(\"ngrok-stable-linux-amd64.zip\")\n",
        "\n",
        "if os.path.exists(\"ngrok\"):\n",
        "    os.remove(\"ngrok\")\n",
        "  \n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ6JZY18fS4G"
      },
      "source": [
        "Start tensorboard and forward port with ngrok"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kele9MJBfAVK"
      },
      "source": [
        "LOG_DIR = 'logs/'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fGr1nvVqduU"
      },
      "source": [
        "Extract ngrok url for accessing tensorboard\n",
        "\n",
        "**Attention**: Sometimes it throws an error like this:\n",
        "```\n",
        "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
        "```\n",
        "If this is the case the easiest way to solve this issue is to delete the ngrok*.zip and ngrok from the Google Drive folder and install them again.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOJxnfekqPg2"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCwiKbPhxVgY"
      },
      "source": [
        "!pip3 install tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8QsqbYA53MI"
      },
      "source": [
        "## Training\n",
        "\n",
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1xgAd-K4Q30"
      },
      "source": [
        "# %tensorflow_version 1.x\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import json\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from datetime import datetime\n",
        "from utils.default_config_setup import get_config, get_options, get_datasets\n",
        "from trainers.AE import AE\n",
        "from trainers.VAE import VAE\n",
        "from trainers.CE import CE\n",
        "from trainers.ceVAE import ceVAE\n",
        "from trainers.GMVAE import GMVAE\n",
        "from trainers.fAnoGAN import fAnoGAN\n",
        "from trainers.AnoVAEGAN import AnoVAEGAN\n",
        "from trainers.WAE import WAEGAN\n",
        "from models import autoencoder, variational_autoencoder, context_encoder_variational_autoencoder,gaussian_mixture_variational_autoencoder,fanogan,constrained_autoencoder,anovaegan, WAEGAN\n",
        "from utils import Evaluation\n",
        "from utils.default_config_setup import get_config, get_options, get_datasets, Dataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xogLARJl_B0K"
      },
      "source": [
        "Set paths to datasets and where to save checkpoints and evaluations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgkGf2LO35hI"
      },
      "source": [
        "def get_CONFIG(timestamp=None):\n",
        "  current_time = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "  if timestamp:\n",
        "    current_time=timestamp\n",
        "  dataset_root = \"path/to/dataset/folder\"\n",
        "  save_dir = \"path/to/save/directory\"\n",
        "  CONFIG = {\n",
        "    \"BRAINWEBDIR\": os.path.join(dataset_root, 'Brainweb'),\n",
        "    \"CHECKPOINTDIR\": os.path.join(save_dir, 'checkpoints', current_time),\n",
        "    \"SAMPLEDIR\": os.path.join(save_dir, 'sample_dir', current_time),\n",
        "  }\n",
        "  return CONFIG"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L41jcwBrqkev"
      },
      "source": [
        "### Manual Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-a9c5c4qaiK"
      },
      "source": [
        "#### Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q8IFuKHqEiI"
      },
      "source": [
        "**AE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSAUx0xsxVga"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBobdPWvXBsl"
      },
      "source": [
        "dataset = Dataset.BRAINWEB\n",
        "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
        "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
        "datasetHC, datasetPC = get_datasets(options, dataset)\n",
        "config = get_config(trainer=AE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
        "\n",
        "# Create an instance of the model and train it\n",
        "model = AE(tf.Session(), config, network=autoencoder.autoencoder)\n",
        "\n",
        "# Train it\n",
        "model.train(datasetHC)\n",
        "\n",
        "# Evaluate\n",
        "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-pIg1uHQufK"
      },
      "source": [
        "**VAE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia25A9wli8d6"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "dataset = Dataset.BRAINWEB\n",
        "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
        "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
        "datasetHC, datasetPC = get_datasets(options, dataset)\n",
        "config = get_config(trainer=VAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
        "\n",
        "# Create an instance of the model and train it\n",
        "model = VAE(tf.Session(), config, network=variational_autoencoder.variational_autoencoder)\n",
        "\n",
        "# Train it\n",
        "model.train(datasetHC)\n",
        "\n",
        "# Evaluate\n",
        "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2WmjqCqp3S4"
      },
      "source": [
        "#### Context Encoding Auto-Encoder\n",
        "\n",
        "Paper: [Context-encoding Variational Autoencoder for Unsupervised Anomaly Detection](https://arxiv.org/abs/1812.05941)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsxKL2xIXhrL"
      },
      "source": [
        "**CE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed4PbNOc2P50"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "dataset = Dataset.Brainweb\n",
        "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
        "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
        "datasetHC, datasetPC = get_datasets(options, dataset)\n",
        "config = get_config(trainer=CE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
        "\n",
        "# Create an instance of the model and train it\n",
        "model = CE(tf.Session(), config, network=autoencoder.autoencoder)\n",
        "\n",
        "# Train it\n",
        "model.train(datasetHC)\n",
        "\n",
        "# Evaluate\n",
        "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlPoFhpyLgqs"
      },
      "source": [
        "**CEVAE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ujv7TbWVuA5"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "dataset = Dataset.Brainweb\n",
        "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
        "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
        "datasetHC, datasetPC = get_datasets(options, dataset)\n",
        "config = get_config(trainer=ceVAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
        "\n",
        "config.use_gradient_based_restoration = 0.002\n",
        "\n",
        "# Create an instance of the model and train it\n",
        "model = ceVAE(tf.Session(), config, network=context_encoder_variational_autoencoder.context_encoder_variational_autoencoder)\n",
        "\n",
        "# Train it\n",
        "model.train(datasetHC)\n",
        "\n",
        "# Evaluate\n",
        "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Oc6ISRcqJMI"
      },
      "source": [
        "#### Gaussian Mixture Variational Auto-Encoder\n",
        "\n",
        "Paper: [Unsupervised Lesion Detection via Image Restoration with a Normative Prior](https://openreview.net/forum?id=S1xg4W-leV)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5HNY5v-qCxO"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "dataset = Dataset.BRAINWEB\n",
        "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
        "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
        "datasetHC, datasetPC = get_datasets(options, dataset)\n",
        "config = get_config(trainer=GMVAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
        "\n",
        "config.dim_c = 9\n",
        "config.dim_z = 128\n",
        "config.dim_w = 1\n",
        "config.c_lambda = 1\n",
        "config.restore_lr = 1e-3\n",
        "config.restore_steps = 10\n",
        "config.tv_lambda = 0.0\n",
        "\n",
        "# Create an instance of the model and train it\n",
        "model = GMVAE(tf.Session(), config, network=gaussian_mixture_variational_autoencoder.gaussian_mixture_variational_autoencoder)\n",
        "\n",
        "# Train it\n",
        "model.train(datasetHC)\n",
        "\n",
        "# Evaluate\n",
        "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdIb36bv-yji"
      },
      "source": [
        "#### f-AnoGAN\n",
        "\n",
        "Paper: [f-AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks.](https://www.ncbi.nlm.nih.gov/pubmed/30831356)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj70VsVlAjIj"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "dataset = Dataset.BRAINWEB\n",
        "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
        "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
        "datasetHC, datasetPC = get_datasets(options, dataset)\n",
        "config = get_config(trainer=fAnoGAN, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
        "\n",
        "config.kappa = 1.0\n",
        "config.scale = 10.0\n",
        "\n",
        "# Create an instance of the model and train it\n",
        "model = fAnoGAN(tf.Session(), config, network=fanogan.fanogan)\n",
        "\n",
        "# Train it\n",
        "model.train(datasetHC)\n",
        "\n",
        "# Evaluate\n",
        "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aMjd0DR236b"
      },
      "source": [
        "#### AnoVAEGAN\n",
        "\n",
        "Paper: [Deep autoencoding models for unsupervised anomaly segmentation in brain MR images](https://arxiv.org/abs/1804.04488)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdHKBg3B2-6W"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "dataset = Dataset.BRAINWEB\n",
        "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
        "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
        "datasetHC, datasetPC = get_datasets(options, dataset)\n",
        "config = get_config(trainer=AnoVAEGAN, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
        "\n",
        "# Create an instance of the model and train it\n",
        "model = AnoVAEGAN(tf.Session(), config, network=anovaegan.anovaegan)\n",
        "\n",
        "# Train it\n",
        "model.train(datasetHC)\n",
        "\n",
        "# Evaluate\n",
        "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_BEQfOd0SYD"
      },
      "source": [
        "#### WAEGAN\r\n",
        "\r\n",
        "Paper: [Wasserstein Auto-Encoders](https://arxiv.org/abs/1711.01558)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hclZeagWA6Rf"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "dataset = Dataset.BRAINWEB\n",
        "options = get_options(batchsize=8, learningrate=0.0001, numEpochs=2, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
        "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
        "datasetHC, datasetPC = get_datasets(options, dataset)\n",
        "config = get_config(trainer=WAEGAN, options=options, optimizer='ADAM', intermediateResolutions=[16, 16], dropout_rate=0.1, dataset=datasetHC)\n",
        "\n",
        "config.kappa = 1.0\n",
        "config.scale = 10.0\n",
        "\n",
        "# Create an instance of the model and train it\n",
        "model = WAEGAN(tf.Session(), config, network=WAEGAN.WAEGAN)\n",
        "\n",
        "# Train it\n",
        "model.train(datasetHC)\n",
        "\n",
        "# Evaluate\n",
        "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}